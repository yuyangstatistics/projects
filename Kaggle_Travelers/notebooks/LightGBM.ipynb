{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about the best tuned LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, VotingClassifier)\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read full training data set\n",
    "df_train = pd.read_csv('../data/train_data_clean_5_grouped.csv')\n",
    "gender_dummies = pd.get_dummies(df_train['gender'], \n",
    "                             prefix = 'gender', drop_first = True)\n",
    "df_train = pd.concat([df_train, gender_dummies], axis = 1)\n",
    "df_train.drop([\"gender\"], axis = 1, inplace = True)\n",
    "\n",
    "living_status_dummies = pd.get_dummies(df_train['living_status'], \n",
    "                             prefix = 'living_status', drop_first = True)\n",
    "df_train = pd.concat([df_train, living_status_dummies], axis = 1)\n",
    "df_train.drop([\"living_status\"], axis = 1, inplace = True)\n",
    "\n",
    "state_dummies = pd.get_dummies(df_train['state'], \n",
    "                               prefix = 'state', drop_first = True)\n",
    "df_train = pd.concat([df_train, state_dummies], axis = 1)\n",
    "df_train.drop([\"state\"], axis = 1, inplace = True)\n",
    "\n",
    "df_train = df_train.sample(frac=1, random_state=5)\n",
    "df_train['new_param'] = df_train.apply(lambda col: col['safty_rating']/(col['past_num_of_claims']+1), axis=1)\n",
    "#df_train['prct_payout'] = df_train.apply(lambda col: col['claim_est_payout']/(col['annual_income']), axis=1)\n",
    "#df_train['age_over_safety'] = df_train.apply(lambda col: col['age_of_driver']/(col['safty_rating']+1), axis=1)\n",
    "df_train.set_index('claim_number', inplace=True)\n",
    "df_train.sort_index(inplace=True)\n",
    "df_train.drop(['claim_date','fraud_claim_date','fraud_zip_code',\n",
    "        \"fraud_gender\", \"fraud_marital_status\", 'fraud_accident_site', 'fraud_high_education_ind',\n",
    "         \"fraud_address_change_ind\", \"fraud_living_status\", \"fraud_witness_present_ind\", \n",
    "         \"fraud_policy_report_filed_ind\", \"fraud_channel\", \"fraud_vehicle_category\",\n",
    "         'fraud_vehicle_color', 'fraud_state', 'SP_Index', 'Unem_rate'], axis = 1, inplace = True)\n",
    "df_train = df_train.filter(regex=\"^(?!state_).*$\")\n",
    "df_train = df_train.filter(regex=\"^(?!vehicle_color_).*$\")\n",
    "df_train = df_train.filter(regex=\"^(?!claim_day_).*$\")\n",
    "df_train = df_train.filter(regex=\"^(?!claim_month_).*$\")\n",
    "\n",
    "train_lgb = df_train.copy()\n",
    "\n",
    "\n",
    "# read full testing data set\n",
    "df_test = pd.read_csv('../data/test_data_clean_5_grouped.csv')\n",
    "gender_dummies = pd.get_dummies(df_test['gender'], \n",
    "                             prefix = 'gender', drop_first = True)\n",
    "df_test = pd.concat([df_test, gender_dummies], axis = 1)\n",
    "df_test.drop([\"gender\"], axis = 1, inplace = True)\n",
    "\n",
    "living_status_dummies = pd.get_dummies(df_test['living_status'], \n",
    "                             prefix = 'living_status', drop_first = True)\n",
    "df_test = pd.concat([df_test, living_status_dummies], axis = 1)\n",
    "df_test.drop([\"living_status\"], axis = 1, inplace = True)\n",
    "\n",
    "state_dummies = pd.get_dummies(df_test['state'], \n",
    "                               prefix = 'state', drop_first = True)\n",
    "df_test = pd.concat([df_test, state_dummies], axis = 1)\n",
    "df_test.drop([\"state\"], axis = 1, inplace = True)\n",
    "\n",
    "#df_test = df_test.sample(frac=1, random_state=5)\n",
    "df_test['new_param'] = df_test.apply(lambda col: col['safty_rating']/(col['past_num_of_claims']+1), axis=1)\n",
    "#df_test['prct_payout'] = df_test.apply(lambda col: col['claim_est_payout']/(col['annual_income']), axis=1)\n",
    "#df_test['age_over_safety'] = df_test.apply(lambda col: col['age_of_driver']/(col['safty_rating']+1), axis=1)\n",
    "\n",
    "df_test.set_index('claim_number', inplace=True)\n",
    "df_test.sort_index(inplace=True)\n",
    "df_test.drop(['claim_date','fraud_claim_date','fraud_zip_code',\n",
    "        \"fraud_gender\", \"fraud_marital_status\", 'fraud_accident_site', 'fraud_high_education_ind',\n",
    "         \"fraud_address_change_ind\", \"fraud_living_status\", \"fraud_witness_present_ind\", \n",
    "         \"fraud_policy_report_filed_ind\", \"fraud_channel\", \"fraud_vehicle_category\",\n",
    "         'fraud_vehicle_color', 'fraud_state', 'SP_Index', 'Unem_rate'], axis = 1, inplace = True)\n",
    "df_test = df_test.filter(regex=\"^(?!state_).*$\")\n",
    "df_test = df_test.filter(regex=\"^(?!vehicle_color_).*$\")\n",
    "df_test = df_test.filter(regex=\"^(?!claim_day_).*$\")\n",
    "df_test = df_test.filter(regex=\"^(?!claim_month_).*$\")\n",
    "\n",
    "test_lgb = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'boosting_type':'gbdt',  'objective':'binary', 'num_boost_round':800,\n",
    "               'feature_fraction': .321, 'bagging_fraction':0.50, 'min_child_samples':100,  \n",
    "               'min_child_weigh':35, 'max_depth':3, 'num_leaves':2, 'learing_rate':0.15,\n",
    "               'reg_alpha':5, 'reg_lambda': 1.1, 'metric':'auc', 'max_bin': 52,\n",
    "               'colsample_bytree': 0.9, 'subsample': 0.8, 'is_unbalance': 'true'\n",
    "}\n",
    "\n",
    "y_train = train_lgb[\"fraud\"]\n",
    "X_train = train_lgb.drop(\"fraud\", 1)\n",
    "\n",
    "lgbm = LGBMClassifier(**lgbm_params)\n",
    "lgbm.fit(X_train.values, y_train.values)\n",
    "y_preds = lgbm.predict_proba(test_lgb.values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lgb['fraud'] = y_preds\n",
    "results = test_lgb.filter(['fraud'], axis=1)\n",
    "results.to_csv('../data/predictions/prediction_lightgbm.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
