{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about how to add grouped-by means as the new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data\n",
    "train = pd.read_csv(\"../data/train_data_clean3.csv\")\n",
    "test = pd.read_csv(\"../data/test_data_clean3.csv\")\n",
    "raw_train = pd.read_csv('../data/raw_train_data.csv')\n",
    "raw_test = pd.read_csv('../data/raw_test_data.csv')\n",
    "\n",
    "\n",
    "## add Unemployment data\n",
    "df1 = pd.read_csv(\"../data/train_data_clean2.csv\")\n",
    "train['Unem_rate'] = df1['Unem_rate']\n",
    "df2 = pd.read_csv('../data/test_data_clean2.csv')\n",
    "test['Unem_rate'] = df2['Unem_rate']\n",
    "\n",
    "## add interest data\n",
    "train_interest = pd.read_csv(\"../data/train_data_interest.csv\")\n",
    "train['Interest_rate'] = train_interest['Interest_rate']\n",
    "test_interest = pd.read_csv(\"../data/test_data_interest.csv\")\n",
    "test['Interest_rate'] = test_interest['Interest_rate']\n",
    "\n",
    "## gender\n",
    "grouped_gender = train[\"fraud\"].groupby(train['gender'])\n",
    "grouped_gender_mean = grouped_gender.mean().to_frame()\n",
    "grouped_gender_mean['gender']=grouped_gender_mean.index\n",
    "grouped_gender_mean['fraud_gender'] = grouped_gender_mean['fraud']\n",
    "grouped_gender_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_gender_mean, on = \"gender\", how = \"left\")\n",
    "test = pd.merge(test, grouped_gender_mean, on = \"gender\", how = \"left\")\n",
    "\n",
    "## marital_status\n",
    "grouped_marital_status = train[\"fraud\"].groupby(train['marital_status'])\n",
    "grouped_marital_status_mean = grouped_marital_status.mean().to_frame()\n",
    "grouped_marital_status_mean['marital_status']=grouped_marital_status_mean.index\n",
    "grouped_marital_status_mean['fraud_marital_status'] = grouped_marital_status_mean['fraud']\n",
    "grouped_marital_status_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_marital_status_mean, on = \"marital_status\", how = \"left\")\n",
    "test = pd.merge(test, grouped_marital_status_mean, on = \"marital_status\", how = \"left\")\n",
    "\n",
    "## high_education_ind\n",
    "grouped_high_education_ind = train[\"fraud\"].groupby(train['high_education_ind'])\n",
    "grouped_high_education_ind_mean = grouped_high_education_ind.mean().to_frame()\n",
    "grouped_high_education_ind_mean['high_education_ind']=grouped_high_education_ind_mean.index\n",
    "grouped_high_education_ind_mean['fraud_high_education_ind'] = grouped_high_education_ind_mean['fraud']\n",
    "grouped_high_education_ind_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_high_education_ind_mean, on = \"high_education_ind\", how = \"left\")\n",
    "test = pd.merge(test, grouped_high_education_ind_mean, on = \"high_education_ind\", how = \"left\")\n",
    "\n",
    "## address_change_ind\n",
    "grouped_address_change_ind = train[\"fraud\"].groupby(train['address_change_ind'])\n",
    "grouped_address_change_ind_mean = grouped_address_change_ind.mean().to_frame()\n",
    "grouped_address_change_ind_mean['address_change_ind']=grouped_address_change_ind_mean.index\n",
    "grouped_address_change_ind_mean['fraud_address_change_ind'] = grouped_address_change_ind_mean['fraud']\n",
    "grouped_address_change_ind_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_address_change_ind_mean, on = \"address_change_ind\", how = \"left\")\n",
    "test = pd.merge(test, grouped_address_change_ind_mean, on = \"address_change_ind\", how = \"left\")\n",
    "\n",
    "## living_status\n",
    "grouped_living_status = train[\"fraud\"].groupby(train['living_status'])\n",
    "grouped_living_status_mean = grouped_living_status.mean().to_frame()\n",
    "grouped_living_status_mean['living_status']=grouped_living_status_mean.index\n",
    "grouped_living_status_mean['fraud_living_status'] = grouped_living_status_mean['fraud']\n",
    "grouped_living_status_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_living_status_mean, on = \"living_status\", how = \"left\")\n",
    "test = pd.merge(test, grouped_living_status_mean, on = \"living_status\", how = \"left\")\n",
    "\n",
    "## zip_code\n",
    "grouped_zip_code = train[\"fraud\"].groupby(train['zip_code'])\n",
    "grouped_zip_code_mean = grouped_zip_code.mean().to_frame()\n",
    "grouped_zip_code_mean['zip_code']=grouped_zip_code_mean.index\n",
    "grouped_zip_code_mean['fraud_zip_code'] = grouped_zip_code_mean['fraud']\n",
    "grouped_zip_code_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_zip_code_mean, on = \"zip_code\", how = \"left\")\n",
    "test = pd.merge(test, grouped_zip_code_mean, on = \"zip_code\", how = \"left\")\n",
    "\n",
    "## claim_date\n",
    "grouped_claim_date = train[\"fraud\"].groupby(train['claim_date'])\n",
    "grouped_claim_date_mean = grouped_claim_date.mean().to_frame()\n",
    "grouped_claim_date_mean['claim_date']=grouped_claim_date_mean.index\n",
    "grouped_claim_date_mean['fraud_claim_date'] = grouped_claim_date_mean['fraud']\n",
    "grouped_claim_date_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_claim_date_mean, on = \"claim_date\", how = \"left\")\n",
    "test = pd.merge(test, grouped_claim_date_mean, on = \"claim_date\", how = \"left\")\n",
    "\n",
    "## witness_present_ind\n",
    "grouped_witness_present_ind = train[\"fraud\"].groupby(train['witness_present_ind'])\n",
    "grouped_witness_present_ind_mean = grouped_witness_present_ind.mean().to_frame()\n",
    "grouped_witness_present_ind_mean['witness_present_ind']=grouped_witness_present_ind_mean.index\n",
    "grouped_witness_present_ind_mean['fraud_witness_present_ind'] = grouped_witness_present_ind_mean['fraud']\n",
    "grouped_witness_present_ind_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_witness_present_ind_mean, on = \"witness_present_ind\", how = \"left\")\n",
    "test = pd.merge(test, grouped_witness_present_ind_mean, on = \"witness_present_ind\", how = \"left\")\n",
    "\n",
    "## policy_report_filed_ind\n",
    "grouped_policy_report_filed_ind = train[\"fraud\"].groupby(train['policy_report_filed_ind'])\n",
    "grouped_policy_report_filed_ind_mean = grouped_policy_report_filed_ind.mean().to_frame()\n",
    "grouped_policy_report_filed_ind_mean['policy_report_filed_ind']=grouped_policy_report_filed_ind_mean.index\n",
    "grouped_policy_report_filed_ind_mean['fraud_policy_report_filed_ind'] = grouped_policy_report_filed_ind_mean['fraud']\n",
    "grouped_policy_report_filed_ind_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_policy_report_filed_ind_mean, on = \"policy_report_filed_ind\", how = \"left\")\n",
    "test = pd.merge(test, grouped_policy_report_filed_ind_mean, on = \"policy_report_filed_ind\", how = \"left\")\n",
    "\n",
    "## state\n",
    "grouped_state = train[\"fraud\"].groupby(train['state'])\n",
    "grouped_state_mean = grouped_state.mean().to_frame()\n",
    "grouped_state_mean['state']=grouped_state_mean.index\n",
    "grouped_state_mean['fraud_state'] = grouped_state_mean['fraud']\n",
    "grouped_state_mean.drop('fraud', axis = 1, inplace = True)\n",
    "train = pd.merge(train, grouped_state_mean, on = \"state\", how = \"left\")\n",
    "test = pd.merge(test, grouped_state_mean, on = \"state\", how = \"left\")\n",
    "\n",
    "## accident_site\n",
    "grouped_accident_site = raw_train[\"fraud\"].groupby(raw_train['accident_site'])\n",
    "grouped_accident_site_mean = grouped_accident_site.mean().to_frame()\n",
    "grouped_accident_site_mean['accident_site']=grouped_accident_site_mean.index\n",
    "grouped_accident_site_mean['fraud_accident_site'] = grouped_accident_site_mean['fraud']\n",
    "grouped_accident_site_mean.drop('fraud', axis = 1, inplace = True)\n",
    "raw_train = pd.merge(raw_train, grouped_accident_site_mean, on = \"accident_site\", how = \"left\")\n",
    "train['fraud_accident_site'] = raw_train['fraud_accident_site']\n",
    "raw_test = pd.merge(raw_test, grouped_accident_site_mean, on = \"accident_site\", how = \"left\")\n",
    "test['fraud_accident_site'] = raw_test['fraud_accident_site']\n",
    "grouped_accident_site_mean\n",
    "\n",
    "## channel\n",
    "grouped_channel = raw_train[\"fraud\"].groupby(raw_train['channel'])\n",
    "grouped_channel_mean = grouped_channel.mean().to_frame()\n",
    "grouped_channel_mean['channel']=grouped_channel_mean.index\n",
    "grouped_channel_mean['fraud_channel'] = grouped_channel_mean['fraud']\n",
    "grouped_channel_mean.drop('fraud', axis = 1, inplace = True)\n",
    "raw_train = pd.merge(raw_train, grouped_channel_mean, on = \"channel\", how = \"left\")\n",
    "train['fraud_channel'] = raw_train['fraud_channel']\n",
    "raw_test = pd.merge(raw_test, grouped_channel_mean, on = \"channel\", how = \"left\")\n",
    "test['fraud_channel'] = raw_test['fraud_channel']\n",
    "\n",
    "## vehicle_category\n",
    "grouped_vehicle_category = raw_train[\"fraud\"].groupby(raw_train['vehicle_category'])\n",
    "grouped_vehicle_category_mean = grouped_vehicle_category.mean().to_frame()\n",
    "grouped_vehicle_category_mean['vehicle_category']=grouped_vehicle_category_mean.index\n",
    "grouped_vehicle_category_mean['fraud_vehicle_category'] = grouped_vehicle_category_mean['fraud']\n",
    "grouped_vehicle_category_mean.drop('fraud', axis = 1, inplace = True)\n",
    "raw_train = pd.merge(raw_train, grouped_vehicle_category_mean, on = \"vehicle_category\", how = \"left\")\n",
    "train['fraud_vehicle_category'] = raw_train['fraud_vehicle_category']\n",
    "raw_test = pd.merge(raw_test, grouped_vehicle_category_mean, on = \"vehicle_category\", how = \"left\")\n",
    "test['fraud_vehicle_category'] = raw_test['fraud_vehicle_category']              \n",
    "\n",
    "## vehicle_color\n",
    "grouped_vehicle_color = raw_train[\"fraud\"].groupby(raw_train['vehicle_color'])\n",
    "grouped_vehicle_color_mean = grouped_vehicle_color.mean().to_frame()\n",
    "grouped_vehicle_color_mean['vehicle_color']=grouped_vehicle_color_mean.index\n",
    "grouped_vehicle_color_mean['fraud_vehicle_color'] = grouped_vehicle_color_mean['fraud']\n",
    "grouped_vehicle_color_mean.drop('fraud', axis = 1, inplace = True)\n",
    "raw_train = pd.merge(raw_train, grouped_vehicle_color_mean, on = \"vehicle_color\", how = \"left\")\n",
    "train['fraud_vehicle_color'] = raw_train['fraud_vehicle_color']\n",
    "raw_test = pd.merge(raw_test, grouped_vehicle_color_mean, on = \"vehicle_color\", how = \"left\")\n",
    "test['fraud_vehicle_color'] = raw_test['fraud_vehicle_color']              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_data_clean_4_grouped.csv', index = False)\n",
    "test.to_csv('test_data_clean_4_grouped.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
